package org.dcu.datacollector;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SaveMode;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.expressions.UserDefinedFunction;
import org.apache.spark.sql.types.DataTypes;
import org.dcu.database.DcuSparkConnectionManager;
import org.dcu.database.MoralisConnectionManager;

import static org.apache.spark.sql.functions.*;
import static org.dcu.util.RandomNameGenerator.generateRandomMintersName;


/**
 * This will persist output in one table
 * <p>
 * 1. trades_by_collection
 * <p>
 * that can be used to create two metrics
 * <p>
 * 1. Top traded NFT collections
 * 2. Least traded NFT collections
 */
public class CollectionMinters {

    public static final MoralisConnectionManager MORALIS_CONNECTION_MANAGER = new MoralisConnectionManager();
    public static final DcuSparkConnectionManager DCU_SPARK_CONNECTION_MANAGER = new DcuSparkConnectionManager();
    private static final int NUM_PARTITIONS = 128;

    private static String tableName = "full_parsed_nft_contract_data"; // this table is generated by spark

    public static void findTopMintersAndTopMintedCollections(SparkSession spark) {

        System.out.println(">>>> Finding Top Minters from table: " + tableName);

        UserDefinedFunction randomNameUDF = udf((String s) -> generateRandomMintersName(), DataTypes.StringType);

        spark.read()
                .jdbc(MORALIS_CONNECTION_MANAGER.getUrl(),
                        tableName, "id", 0, 125000, 128,
                        MORALIS_CONNECTION_MANAGER.getProps())
                .select(col("minter_address"),
                        col("nft_address"),
                        col("token_id"),
                        col("name"),
                        col("contract_type"),
                        col("symbol"))
                .cache()
                .createOrReplaceTempView("tempView");

        //Top minters
        // Query to count the number of records for each minterAddress
        String query_top_minters = "select minter_address, count(*) as cnt from tempView group by minter_address order by cnt desc";
        String query_top_minted_coll = "select nft_address, name, count(*) as cnt from tempView group by nft_address, name order by cnt desc";
        String query_contract_type_count = "select contract_type, count(*) as cnt from tempView group by contract_type order by cnt desc";
        String query_contract_types_in_collection = "select nft_address, contract_type, count(*) as cnt " +
                "from tempView group by nft_address, contract_type order by nft_address, contract_type, cnt desc";

        Dataset<Row> df_1 = spark.sql(query_top_minters)
                .repartition(col("minter_address"))
                .sortWithinPartitions(col("cnt").desc())
                .withColumn("minter_name", randomNameUDF.apply(col("minter_address")));

        df_1.write().mode(SaveMode.Overwrite)
                .jdbc(DCU_SPARK_CONNECTION_MANAGER.getUrl(), "full_top_minters", DCU_SPARK_CONNECTION_MANAGER.getProps());

        //df_1.show();
        System.out.println(" --------------- Data persisted into full_top_minters ----------------------- ");
/* Sample output
+--------------------+---+
|       minterAddress|cnt|
+--------------------+---+
|                null|242|
|0x232036ed540221a...|162|
|0x6bcbe6c086cc668...|120|
|0x98bd3cd04e599bc...|113|
|0x2a8f200c4a79c66...|104|
|0xf7a926e197e2a07...|102|
|0x727ac56455e8441...|100|
|0x0be0cce50e087c1...|100|
|0xa0a39727f22fae7...|100|
|0x9b353523f266b3e...|100|
|0x98849eca30be416...|100|
|0xf916719c7251e10...| 90|
|0xbc8dafeaca658ae...| 89|
|0xb154587a54aa67f...| 83|
|0x828a33a01145a34...| 83|
|0xa8eb4ee8087892b...| 72|
|0x082a7c12a2ef221...| 66|
|0xe11473d82992110...| 63|
|0xf09c81223fda440...| 57|
|0xdf7f8984b4a8105...| 56|
+--------------------+---+
only showing top 20 rows
* */


        // Execute the query and save the result
        Dataset<Row> df_2 = spark.sql(query_top_minted_coll)
                .withColumn("row_num", monotonically_increasing_id())
                .cache();

        df_2.repartitionByRange(NUM_PARTITIONS, col("row_num"))
                .sortWithinPartitions(col("row_num").asc())
                .write()
                .mode(SaveMode.Overwrite)
                .jdbc(DCU_SPARK_CONNECTION_MANAGER.getUrl(), "full_top_minted_collections", DCU_SPARK_CONNECTION_MANAGER.getProps());

        //df_2.show();
        System.out.println(" --------------- Data persisted into full_top_minted_collections ----------------------- ");
/*
* Sample output
+--------------------+--------------+----+
|          nftAddress|          name| cnt|
+--------------------+--------------+----+
|0x000E49C87d28744...|       Goobers|8687|
|0x00000633Df12288...|         wLoot|1088|
|0x000000000437b3C...|        My NFT| 139|
|0x000000F36EDb9d4...| ShibaInuSpace|  29|
|0x00000000000b7F8...|         zLoot|  29|
|0x00000000fFfD97a...|      Rare QRs|  23|
|0x000000873EE8C0b...|       Unicorn|   3|
|0x00027FFc0FbEd9a...|NFTworldArt102|   1|
|0x0000009FC3Fea00...| ShibaInuSpace|   1|
+--------------------+--------------+----+
*
* */

        // Execute the query and save the result
        Dataset<Row> df_3 = spark.sql(query_contract_type_count)
                .withColumn("row_num", monotonically_increasing_id())
                .cache();

        df_3.repartitionByRange(NUM_PARTITIONS, col("row_num"))
                .sortWithinPartitions(col("row_num").asc())
                .write().mode(SaveMode.Overwrite)
                .jdbc(DCU_SPARK_CONNECTION_MANAGER.getUrl(), "full_contract_type_count", DCU_SPARK_CONNECTION_MANAGER.getProps());

        //df_3.show();
        System.out.println(" --------------- Data persisted into full_contract_type_count ----------------------- ");

        /* Sample output
        ERC721,   13719091
        ERC165,   2021793
        ERC1155,  46806
        null   ,  2310
         */


        // Execute the query and save the result
        Dataset<Row> df_4 = spark.sql(query_contract_types_in_collection)
                .withColumn("row_num", monotonically_increasing_id())
                .cache();

        df_4.repartitionByRange(NUM_PARTITIONS, col("row_num"))
                .sortWithinPartitions(col("row_num").asc())
                .write().mode(SaveMode.Overwrite)
                .jdbc(DCU_SPARK_CONNECTION_MANAGER.getUrl(), "full_contract_types_in_collection", DCU_SPARK_CONNECTION_MANAGER.getProps());

        //df_4.show();
        System.out.println(" --------------- Data persisted into full_contract_types_in_collection ----------------------- ");

/* * Sample output
        0x00000000000b7F8E8E8Ad148f9d53303Bfe20796,   ERC721,   29
        0x000000000437b3CCE2530936156388Bff5578FC3,   ERC721,   139
        0x00000000fFfD97acDc8C5585C818F6b0f946C0eD,   ERC721,   23
        0x000000873EE8C0bE5B00D4b16723519e728A7420,   ERC721,   3
        0x0000009FC3Fea00F2e750632d49E2AfD96878F2a,   ERC721,   1
        0x000000F36EDb9d436Be73cDBf0DCa7dF3E6F3A50,   ERC721,   29
        0x00000633Df1228868270bAdB2B812E12e13fdB91,   ERC721,   1088
        0x00027FFc0FbEd9aC510935aBf860300aF93fe954,   ERC721,   1
        0x000E49C87d2874431567d38FF9548890aB39BAac,   ERC721,   14577
        0x001B4b85192aa034bff1524f181e3a7060e0dC30,   ERC721,   112
*/



    }
}
